{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/segment-anything/blob/main/notebooks/automatic_mask_generator_example.ipynb\">\n",
       "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
       "</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\n",
    "\"\"\"\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/LordElf/fish-diffusion/blob/notebooks-support/notebooks/fish-audio_sample.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir /content/env\n",
    "MINICONDA_INSTALLER_SCRIPT=Miniconda3-py310_23.1.0-1-Linux-x86_64.sh\n",
    "MINICONDA_PREFIX=/content/env\n",
    "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
    "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
    "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /content/env/bin/activate;\\\n",
    "conda create -n fish_diffusion python=3.10 -y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install PyTorch related core dependencies\n",
    "!source /content/env/bin/activate;\\\n",
    "conda activate fish_diffusion;\\\n",
    "conda install \"pytorch>=2.0.0\" \"torchvision>=0.15.0\" \"torchaudio>=2.0.0\" pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/LordElf/fish-diffusion\n",
    "%cd fish-diffusion\n",
    "!git checkout notebooks-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /content/env/bin/activate;\\\n",
    "conda activate fish_diffusion;\\\n",
    "cat requirements.txt | xargs -n 1 pip install;\\\n",
    "pip install -e ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocoder preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /content/env/bin/activate;\\\n",
    "conda activate fish_diffusion;\\\n",
    "python tools/download_nsf_hifigan.py --agree-license"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation\n",
    "```shell\n",
    "dataset\n",
    "├───train\n",
    "│   ├───xxx1-xxx1.wav\n",
    "│   ├───...\n",
    "│   ├───Lxx-0xx8.wav\n",
    "│   └───speaker0 (Subdirectory is also supported)\n",
    "│       └───xxx1-xxx1.wav\n",
    "└───valid\n",
    "    ├───xx2-0xxx2.wav\n",
    "    ├───...\n",
    "    └───xxx7-xxx007.wav\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mount google drive or upload your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft link your dataset to the current diretory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/test-fish-audio/dataset/\"#@param{type:\"string\"}\n",
    "!ln -s $dataset_path dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all data features, such as pitch, text features, mel features, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### if error about torchvision occured, run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !source /content/env/bin/activate;\\\n",
    "# conda activate fish_diffusion;\\\n",
    "# pip uninstall torchvision -y;\\\n",
    "# pip install torchvision  --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /content/env/bin/activate;\\\n",
    "conda activate fish_diffusion;\\\n",
    "python tools/preprocessing/extract_features.py --config configs/svc_hubert_soft.py --path dataset  --clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "training_options = widgets.RadioButtons(\n",
    "    options=['single_gpu', 'multi_gpu', 'multi_node'],\n",
    "    description='Training Options:',\n",
    "    disabled=False\n",
    ")\n",
    "display(training_options)\n",
    "\n",
    "pretrained = widgets.ToggleButtons(\n",
    "    options=['yes', 'no'],\n",
    "    description='Pretrained:',\n",
    "    disabled=False\n",
    ")\n",
    "display(pretrained)\n",
    "\n",
    "resume = widgets.ToggleButtons(\n",
    "    options=['yes', 'no'],\n",
    "    description='Resume:',\n",
    "    disabled=False\n",
    ")\n",
    "display(resume)\n",
    "\n",
    "resume_checkpoint = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter the checkpoint file name',\n",
    "    description='Checkpoint File:',\n",
    "    disabled=resume.value == 'no'\n",
    ")\n",
    "display(resume_checkpoint)\n",
    "\n",
    "pretrain_checkpoint = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Enter the pretrain checkpoint file name',\n",
    "    description='Pretrain Checkpoint:',\n",
    "    disabled=ptrained.value == 'no'\n",
    ")\n",
    "display(pretrain_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume.value == 'yes':\n",
    "    resume_str = f\"--resume {resume_checkpoint.value}\"\n",
    "else:\n",
    "    resume_str = \"\"\n",
    "    \n",
    "if pretrain_checkpoint.value != '':\n",
    "    pretrain_str = f\"--pretrain {pretrain_checkpoint.value}\"\n",
    "else:\n",
    "    pretrain_str = ''\n",
    "\n",
    "if training_options.value == \"single_gpu\":\n",
    "    cmd = f\"tools/diffusion/train.py --config configs/svc_hubert_soft.py {resume_str} {pretrain_str}\"\n",
    "elif training_options.value == \"multi_gpu\":\n",
    "    cmd = f\"tools/diffusion/train.py --config configs/svc_hubert_soft.py --gpus 2 {resume_str} {pretrain_str}\"\n",
    "elif training_options.value == \"multi_node\":\n",
    "    cmd = f\"-m torch.distributed.launch --nnodes 2 --nproc_per_node 2 train.py --config configs/svc_hubert_soft.py {resume_str} {pretrain_str}\"\n",
    "\n",
    "!source /content/env/bin/activate;\\\n",
    "conda activate fish_diffusion;\\\n",
    "python {cmd}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish-audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
