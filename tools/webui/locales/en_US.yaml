main_ui:
  Intro_tab:
    title: "Intro"
    terms_of_use: "Terms of Use for Fish Diffusion"
    terms_of_use_content: "1. Obtaining Authorization and Intellectual Property Infringement: The user is solely accountable for acquiring the necessary authorization for any datasets utilized in their training process and assumes full responsibility for any infringement issues arising from the utilization of the input source. Fish Diffusion and its developers disclaim all responsibility for any complications that may emerge due to the utilization of unauthorized datasets.

    2. BSD-3-Clause-Clear License: Fish Diffusion is distributed under the BSD-3-Clause-Clear License, which confers upon the user the privilege to employ it for any purpose, encompassing commercial applications. For more detail, see the LICENSE file.

    3. Proper Attribution: Any derivative works based on Fish Diffusion must explicitly acknowledge the project and its license. In the event of distributing Fish Diffusion's code or disseminating results generated by this project, the user is obliged to cite the original author and source code (Fish Diffusion).

    4. Audiovisual Content and AI-generated Disclosure: All derivative works created using Fish Diffusion, including audio or video materials, must explicitly acknowledge the utilization of the Fish Diffusion project and declare that the content is AI-generated. If incorporating videos or audio published by third parties, the original links must be furnished.

    6. Agreement to Terms: By persisting in the use of Fish Diffusion, the user unequivocally consents to the terms and conditions delineated in this document. Neither Fish Diffusion nor its developers shall be held liable for any subsequent difficulties that may transpire."
    content: "## Summary

    Using Diffusion Model to solve different voice generating tasks. Compared with the original diffsvc repository, the advantages and disadvantages of this repository are as follows:

    + Support multi-speaker

    + The code structure of this repository is simpler and easier to understand, and all modules are decoupled

    + Support [44.1khz Diff Singer community vocoder](https://openvpi.github.io/vocoders/)

    + Support multi-machine multi-devices training, support half-precision training, save your training speed and memory
    "
  Generate_Config_tab:
    title: "Generate Config"
    content: "Generate config file for training and inference.

    The Default setting should be:

    + diff_svc_v2 + step + base

    + hifi_svc + exponential + hifi_svc,
    "
    genrate_btn: "Generate"
    model_options:
      - "diff_svc_v2"
      - "hifi_svc"
      - "hifi_svc_v2"
    optimizer_scheduler_options:
      - "exponential"
      - "step"
      - "warmup_cosine"
      - "warmup_cosine_finetune"
    trainer_options:
      - "base"
      - "hifi_svc"
  Train_tab:
    title: "Train and Preprocessing"
    config_path_label: "Config Path"
    preprocessing:
      title: "Preprocessing"
      btn: "Extract Feature"
      show_log_btn: "Refresh Log"
      num_workers: "Number of Workers"
      logfile_label: "Log File Name"
      log_viewer_label: "Preprocessing Log Viewer (live updates)"
    train:
      title: "Train"
      btn: "Start Training"
      entity: "Entity for wandb"
      resume: "Resume training using the latest ckpt"
      resume_id: "Resume Id for wandb"
      ckpt: "Checkpoint path"
      run_name: "Run Name for wandb"
      pretrained: "use pretrained model"
      output: "Output path"
      log: "UI Log path for training"
      log_viewer_label: "Training Log Viewer (live updates)"
  Inference_tab:
    title: "Inference"
    content: ""
    inference_btn: "Inference"
    config_path_label: "Config Path"
    input_path_label: "Input Path"
    output_path_label: "Output Path"
    speaker_label: "Speaker"
    pitch_adjust_label: "Pitch Adjust"
    pitches_path_label: "Pitches Path"
    extract_vocals_label: "Extract Vocals"
    sampler_progress_label: "Sampler Progress"
    sampler_interval_label: "Sampler Interval"
    silence_threshold_label: "Silence Threshold"
    max_slice_duration_label: "Max Slice Duration"
    min_silence_duration_label: "Min Silence Duration"
    skip_steps_label: "Skip Steps"
    inference_btn: "Inference"
    checkpoint_path_label: "Checkpoint Path"
